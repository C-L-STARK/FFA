import{_ as a,c as e,o as t,a3 as r,j as l}from"./chunks/framework.CVqs_p0L.js";const b=JSON.parse('{"title":"Free Meta Llama-2 7B","description":"","frontmatter":{"layout":"doc"},"headers":[],"relativePath":"chat/Meta-Llama-2-7B.md","filePath":"chat/Meta-Llama-2-7B.md","lastUpdated":1719761409000}'),o={name:"chat/Meta-Llama-2-7B.md"},c=r('<h1 id="free-meta-llama-2-7b" tabindex="-1">Free Meta Llama-2 7B <a class="header-anchor" href="#free-meta-llama-2-7b" aria-label="Permalink to &quot;Free Meta Llama-2 7B&quot;">​</a></h1><p>7B 模型是 Meta Llama-2 的最基本模型，运行速度较快，生成内容的准确度嘛，当然没有 13B 和 70B 那么好。</p><p>llama-2 7b 和 13b 是比较老的模型了，为了提供一些对比，我们还是将这两篇文章保留了下来。</p><p><a href="https://llama.meta.com/llama3/" target="_blank" rel="noreferrer">llama-3 官网传送门</a></p><h2 id="在线免费体验-加载稍慢-需魔法" tabindex="-1">在线免费体验（加载稍慢，需魔法） <a class="header-anchor" href="#在线免费体验-加载稍慢-需魔法" aria-label="Permalink to &quot;在线免费体验（加载稍慢，需魔法）&quot;">​</a></h2><p>当然，你也可以使用在线体验界面进行在线体验，<code>加载稍慢，耐心等待</code>，而且最好拥有 <a href="https://huggingface.co/" target="_blank" rel="noreferrer">huggingface</a> 的账号。不然会偶尔碰到 gpu 资源使用超过免费限额，需要等待一段时间的情况。</p><blockquote><p>再次注意：需魔法</p></blockquote>',7),s=l("iframe",{src:"https://huggingface-projects-llama-2-7b-chat.hf.space",frameborder:"0",width:"100%",height:"1000"},null,-1),h=[c,s];function n(m,_,d,i,p,f){return t(),e("div",null,h)}const g=a(o,[["render",n]]);export{b as __pageData,g as default};
